I"Ğ<h1 id="paper-review-anomaly-transformer">[Paper review] Anomaly Transformer</h1>

<p>ì‹œê³„ì—´ ë°ì´í„°ì˜ ì´ìƒì¹˜ íƒìƒ‰ ë°©ë²•ë¡ ìœ¼ë¡œì„œ Transformer ë§¤ì»¤ë‹ˆì¦˜ì„ í™œìš©í•œ <strong>Anomaly Transformer</strong>ì— ëŒ€í•´ ë¦¬ë·°í•´ë³´ê² ìŠµë‹ˆë‹¤. ICLR 2022 ì˜ spotlight ë…¼ë¬¸ì´ë¼ê³  í•˜ë„¤ìš”!</p>

<p><em>Xu, Jiehui, et al. â€œAnomaly transformer: Time series anomaly detection with association discrepancy.â€Â arXiv preprint arXiv:2110.02642 (2021)</em></p>

<p>(ë³¸ ë¦¬ë·°ì˜ ëª¨ë“  ìˆ˜ì‹ê³¼ ê·¸ë¦¼ì€ ì› ë…¼ë¬¸ì„ ì°¸ê³ í–ˆìŠµë‹ˆë‹¤.)</p>

<hr />

<h3 id="idea">Idea</h3>
<p><strong>Anomaly Transformer</strong>ëŠ” ì´ë¦„ì—ì„œ ì•Œ ìˆ˜ ìˆë“¯ì´ <em>Transformer</em>ë¥¼ í™œìš©í•˜ì—¬ ì‹œê³„ì—´ ë°ì´í„°ì—ì„œì˜ <em>Anomaly detection</em>ì„ ì˜ í•´ë³´ìëŠ” ëª©ì ì„ ê°€ì§€ê³  ìˆìŠµë‹ˆë‹¤. ì´ìƒì ì„ íƒìƒ‰í•˜ëŠ” ë°©ë²•ìœ¼ë¡œëŠ” reconstruction based ë°©ë²•ì„ ì‚¬ìš©í•˜ê³  ìˆìŠµë‹ˆë‹¤. Unsupervised learningìœ¼ë¡œ ì£¼ì–´ì§„ train ì‹œê³„ì—´ ë°ì´í„°ì˜ íŒ¨í„´ì„ í†µí•´ ì •ìƒ ì‹œê³„ì—´ íŒ¨í„´ì„ ì˜ ì¬êµ¬ì¶• í•˜ë„ë¡ ëª¨í˜•ì„ í•™ìŠµì‹œí‚µë‹ˆë‹¤. ì¶”í›„ì— test setì´ ë“¤ì–´ì™”ì„ ë•Œ, ëª¨í˜•ì´ ì¬êµ¬ì¶•(reconstruction)í•œ ì‹œê³„ì—´ íŒ¨í„´ê³¼ì˜ ë¹„êµë¥¼ í†µí•´ ê·¸ ì°¨ì´ê°€ í° (anomaly scoreê°€ í°) ì§€ì ì„ ì´ìƒì ìœ¼ë¡œ íƒìƒ‰í•˜ëŠ” ë°©ë²•ë¡ ì…ë‹ˆë‹¤. ì´ ë•Œ, ì •ìƒ ì‹œê³„ì—´ íŒ¨í„´ì„ ì˜ í•™ìŠµí•˜ë„ë¡ í•´ì£¼ê¸° ìœ„í•´ Transformerë¥¼ í™œìš©í•©ë‹ˆë‹¤. Self-attentionì„ ì´ìƒì  íƒì§€ì— íŠ¹í™”ë˜ê²Œ ë°”ê¾¼ Anomaly-attentionì„ ì œì•ˆí•˜ì˜€ìŠµë‹ˆë‹¤. ê·¸ëŸ¼ Anomaly Transformerì— ëŒ€í•´ ë³¸ê²©ì ìœ¼ë¡œ ì•Œì•„ë³´ë„ë¡ í•˜ê² ìŠµë‹ˆë‹¤.</p>

<h3 id="anomaly-transformer">Anomaly Transformer</h3>
<p>Anomaly Transformerì˜ architectureëŠ” ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤.</p>

<p align="center">
  <img src="https://decision-J.github.io/assets/Post Images/Anomaly Transformer.png" alt="Anomaly Transformer architecture" />
</p>

<p>Input embedding $X_{0}$ê°€ ë“¤ì–´ì˜¤ë©´ í¬ê²Œ <strong>Anomaly Attenion</strong> layerì™€ Feed Forward layerë¥¼ Lë²ˆ ë°˜ë³µ ìˆ˜í–‰í•˜ë©° input time seriesì˜ patternì„ í•™ìŠµí•˜ê²Œ ë©ë‹ˆë‹¤. ì´í›„ ì´ í•™ìŠµëœ ì •ë³´ë¥¼ ê°€ì§€ê³  ê°€ì¥ ë³´í¸ì ì¸ patternì˜ reconstruction dataë¥¼ ì‚°ì¶œí•˜ëŠ”ë°ìš”! ì´ êµ¬ì¡°ì—ì„œ ê°€ì¥ ì£¼ëª©í•´ì•¼ í•˜ê³ , Anomaly transformerê°€ ë†’ì€ ì„±ëŠ¥ì„ ê°€ì§€ëŠ” ì´ìœ ëŠ” ë‹¨ì—° Anomaly attentionì¼ ê²ƒì…ë‹ˆë‹¤.</p>

<h3 id="anomaly-attention">Anomaly Attention</h3>
<p>Anomaly attentionì€ ê¸°ë³¸ì ì¸ attentionì„ ê°€ì§€ê³  ì €ìë“¤ì´ time series anomaly detectionì— ë§ê²Œ ë§¤ì»¤ë‹ˆì¦˜ì„ ì¡°ê¸ˆ ìˆ˜ì •í•œ í˜•íƒœì…ë‹ˆë‹¤. ê°€ì¥ í° ë¶€ë¶„ì€ attention ë‚´ë¶€ë¥¼ <em>Prior-Association</em>ê³¼ <em>Series-Association</em>ì˜ ë‘ ê°€ì§€ë¡œ ë‚˜ëˆ„ì—ˆë‹¤ëŠ” ê²ƒì…ë‹ˆë‹¤. 
ë¨¼ì € prior associationì€ ì´ë¦„ì—ì„œ ì•Œ ìˆ˜ ìˆë“¯ì´, ëª¨í˜•ì—ì„œ ì‚¬ìš©í•˜ëŠ” Gaussian kernelì˜ ì‹œê·¸ë§ˆë¥¼ í•™ìŠµí•©ë‹ˆë‹¤. Gaussian Kernelì€ attentionì˜ Query, Keyë¥¼ í•™ìŠµí•  ë•Œ ì˜í–¥ì„ ì¤ë‹ˆë‹¤. ì»¤ë„ì„ í†µí•´ ë‹¤ì–‘í•œ íŒ¨í„´ì˜ ì‹œê³„ì—´ ìë£Œì— ì ìš©í•  ìˆ˜ ìˆë‹¤ê³  ì €ìëŠ” ì„¤ëª…í•˜ê³  ìˆìŠµë‹ˆë‹¤. Series asssociationì€ Queryì™€ Keyë¥¼ í•™ìŠµí•˜ëŠ” ë¶€ë¶„ì…ë‹ˆë‹¤. ì €ìë“¤ì€ ì´ ë‘ associationì„ í†µí•´ì„œ(ì •í™•íˆëŠ” prior association) ì‹œê³„ì—´ ìë£Œë¥¼ point-wiseê°€ ì•„ë‹Œ, temporal dependencyë¥¼ í•™ìŠµí•  ìˆ˜ ìˆë‹¤ê³  ì„¤ëª…í•©ë‹ˆë‹¤. Gaussian Kernelì˜ $\sigma$ë¥¼ í†µí•´ì„œ ì¸ì ‘í•œ time pointì— ë” í° ê°€ì¤‘ì¹˜ë¥¼ ì¤„ ìˆ˜ ìˆë‹¤ëŠ” ê²ƒì´ì§€ìš”.</p>

<h3 id="association-discrepancy">Association Discrepancy</h3>
<p>Association DiscrepancyëŠ” ì•ì„œ ì‚´í´ë³¸ prior associationê³¼ series associationê°„ì˜ ì°¨ì´ë¥¼ ê³„ì‚°í•˜ëŠ” ê²ƒì…ë‹ˆë‹¤. ì°¨ì´ë¥¼ ê³„ì‚°í•˜ëŠ” ë°©ë²•ì€ KL divergenceë¥¼ í™œìš©í•˜ì˜€ìœ¼ë©°, KL divergenceì˜ assymetricí•œ ì ì„ ë³´ì™„í•˜ê¸° ìœ„í•´ ìˆœì„œë¥¼ ë°”ê¿”ê°€ë©° ê³„ì‚°í•œ í‰ê· ì„ ì‚¬ìš©í•˜ì˜€ìŠµë‹ˆë‹¤. Association DiscrepancyëŠ” Loss functionì˜ í•œ termìœ¼ë¡œ í¬í•¨ë˜ë©° ê°€ì¤‘ì¹˜ë¥¼ ì—…ë°ì´íŠ¸ í•˜ëŠ”ë° ì‚¬ìš©í•˜ê¸°ë„ í•˜ê³  ì¶”í›„ anomaly scoreë¥¼ ê³„ì‚°í•˜ëŠ” ë°ì—ë„ ì‚¬ìš©ë©ë‹ˆë‹¤.</p>

<p>$$ AssDis(P,S; X) = \frac{1}{L} \sum^L_{l=1}(KL(P^l_i||S^l_i) + KL(S^l_i||P^l_i)) $$
$$ where\,\, i=1,â€¦,N $$</p>

<h3 id="mini-max-association-learning">Mini Max Association Learning</h3>
<p>ì €ìë“¤ì€ Attention ë‚´ë¶€ì— prior &amp; series association ë‘ ê°œì˜ termì´ ìˆëŠ” ë§Œí¼ ì´ë¥¼ í™œìš©í•˜ì—¬ Loss functionì„ ë³‘ë ¬ì ìœ¼ë¡œ êµ¬ì„±í•˜ëŠ” mini max learning strategyë¥¼ ì œì•ˆí•©ë‹ˆë‹¤. ìš°ì„  Anomaly transformerì—ì„œ ì‚¬ìš©í•˜ëŠ” Loss functionì€ ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤.</p>

<table>
  <tbody>
    <tr>
      <td>$$L_{total}(\hat{X}, P, S, \lambda; X) = (|</td>
      <td>X-\hat{X}|</td>
      <td>)^2_F - \lambda \cdot |</td>
      <td>AssDis(P, S; X)|</td>
      <td>$$</td>
    </tr>
  </tbody>
</table>

<p>ìˆ˜ì‹ì„ ë³´ë©´ $\lambda$ termì— ì˜í•´ Association discrepancyê°€ ì¡°ì ˆë¨ì„ ì•Œ ìˆ˜ ìˆìŠµë‹ˆë‹¤. $\lambda$ê°€ 0ë³´ë‹¤ í¬ë©´ ëª¨í˜•ì€ association discrepancyë¥¼ ë” í¬ê²Œ ë§Œë“œëŠ” ë°©í–¥ìœ¼ë¡œ í•™ìŠµì´ ì§„í–‰ë˜ë©°, 0ë³´ë‹¤ ì‘ìœ¼ë©´ ë°˜ëŒ€ë¡œ ì‘ê²Œ ë§Œë“œëŠ” ë°©í–¥ìœ¼ë¡œ í•™ìŠµì´ ì§„í–‰ë©ë‹ˆë‹¤. ì´ ê°œë…ì„ í™œìš©í•œ ê²ƒì´ ë°”ë¡œ <strong>Mini max Strategy</strong> ì…ë‹ˆë‹¤.</p>

<p>Mini maxëŠ” ë§ ê·¸ëŒ€ë¡œ <strong>Minimize phase, Maxmize phase</strong> ë‘ ë¶€ë¶„ìœ¼ë¡œ ë‚˜ëˆ„ì–´ Loss functionì„ ë‹¤ë¥´ê²Œ ì ìš©í•˜ëŠ” ê²ƒì…ë‹ˆë‹¤.</p>

<p>$$ Minimize: L_{Total}(\hat{X}, P, S_{detach}, -\lambda; X) $$
$$ Maximize: L_{Total}(\hat{X}, P_{detach}, S, \lambda; X) $$</p>

<p>ìˆ˜ì‹ì—ì„œ ì•Œ ìˆ˜ ìˆë“¯ì´, Minimize phaseë•ŒëŠ” Prior associationì„ í•™ìŠµí•˜ê³ , Maximize phase ë•ŒëŠ” Series associationì„ í•™ìŠµí•©ë‹ˆë‹¤. ì´ ë•Œ, $\lambda$ì˜ ë¶€í˜¸ì— ë”°ë¼ í•™ìŠµì˜ ë°©í–¥ì´ ë‹¬ë¼ì§€ëŠ” ê²ƒì…ë‹ˆë‹¤. ë…¼ë¬¸ì˜ ê·¸ë¦¼ì„ ë³´ë©´ ì¢€ ë” ì´í•´í•˜ê¸° ì‰½ìŠµë‹ˆë‹¤.</p>

<p align="center">
  <img src="https://decision-J.github.io/assets/Post Images/Anomaly Transformer2.png" />
</p>

<p>ë¨¼ì € ì™¼í¸ì˜ Minimize phaseë¥¼ ë³´ë©´ Loss functionì˜ $\lambda$ ê°€ 0ë³´ë‹¤ ì‘ê¸° ë•Œë¬¸ì—, association discrepancy, ì¦‰, Prior associationê³¼ Series associationì˜ ì°¨ì´ë¥¼ ì‘ê²Œ ë§Œë“¤ì–´ì£¼ëŠ” ë°©í–¥ìœ¼ë¡œ í•™ìŠµë©ë‹ˆë‹¤. ì´ë¥¼ í•´ì„í•´ë³´ë©´ Gausian priorì˜ $\sigma$ë¥¼ ì£¼ì–´ì§„ time series patternì— ê°€ì¥ ì ì ˆí•˜ê²Œ tuningì‹œì¼œì£¼ëŠ” ì‘ì—…ì´ë¼ê³ ë„ í•  ìˆ˜ ìˆì„ ê²ƒ ê°™ìŠµë‹ˆë‹¤.</p>

<p>ì¤‘ìš”í•œ ê²ƒì€ ì˜¤ë¥¸ìª½ì˜ Maxmize phaseì¸ë°ìš”. ì‚¬ì‹¤ìƒ ì´ ë¶€ë¶„ì„ í†µí•´ ëª¨í˜•ì´ Anomalyë¥¼ ì°¾ëŠ”ë‹¤ê³ ë„ í•  ìˆ˜ ìˆê² ìŠµë‹ˆë‹¤. ì• ì„œì™€ëŠ” ë‹¬ë¦¬ $\lambda$ê°€ 0ë³´ë‹¤ í¬ë¯€ë¡œ ë‘ associationê°„ì˜ ì°¨ì´ê°€ ì»¤ì§€ë„ë¡ í•™ìŠµì„ í•˜ê²Œ ë©ë‹ˆë‹¤. ë”°ë¼ì„œ ê·¸ë¦¼ì—ì„œì™€ ê°™ì´ ì‹œê³„ì—´ ë‚´ì—ì„œ anomaly patternì„ ë³´ì´ëŠ” ì‹œì ì—ì„œì˜ ê²½ìš° Association discrepancyê°€ ë” ì»¤ì§€ë„ë¡ (ë²Œì–´ì§€ë„ë¡) í•´ì¤ë‹ˆë‹¤.</p>

<h3 id="association-based-anomaly-criterion">Association-based Anomaly Criterion</h3>

<h3 id="experiments">Experiments</h3>

<hr />
<h3 id="reference">Reference</h3>

<ol>
  <li>Paper: <a href="https://arxiv.org/pdf/2110.02642.pdf">Anomaly Transformer</a></li>
  <li>Youtube: <a href="https://www.youtube.com/watch?v=C3dphckvyn0&amp;ab_channel=%EA%B3%A0%EB%A0%A4%EB%8C%80%ED%95%99%EA%B5%90%EC%82%B0%EC%97%85%EA%B2%BD%EC%98%81%EA%B3%B5%ED%95%99%EB%B6%80DSBA%EC%97%B0%EA%B5%AC%EC%8B%A4">ê³ ë ¤ëŒ€í•™êµ ì‚°ì—…ê²½ì˜ê³µí•™ê³¼ DSBAì—°êµ¬ì‹¤ ì„¸ë¯¸ë‚˜</a></li>
  <li>Github: <a href="https://github.com/thuml/Anomaly-Transformer">Code (Pytorch)</a></li>
</ol>

:ET